#!/bin/bash

# Required parameters:
# @raycast.schemaVersion 1
# @raycast.title Prompt my prompt
# @raycast.mode silent
# @raycast.icon ðŸ¤–
# @raycast.packageName Prompt Tools

# Configuration
OPENAI_API_KEY="XXXXXX"

# System prompt
read -r -d '' SYSTEM_PROMPT <<'EOF'
You are an expert Prompt Architect. Your task is to analyze the user intent within <HUMAN_PROMPT> and transform it into a professional, production-ready Markdown prompt.

YOUR WORKFLOW:
1. Logic Analysis: Internally evaluate the goal, technical constraints, and potential failure points of the human prompt.
2. Structure: Draft the improved prompt using clear Markdown headers and bullet points. 
3. Code Integrity: If the human prompt contains code blocks or specific formatting, you must preserve and integrate them exactly.

RULES:
- NO JSON OUTPUT. All instructions and examples must use Markdown.
- Provide ONLY the final, improved prompt. No preamble, no "Here is the result," and no meta-analysis.
- Use square brackets for missing variables: [SPECIFY: detail].
- If the task is complex, include a "Reasoning" or "Process" section in the output. If the task is simple (e.g., formatting), keep the output direct.

OUTPUT STRUCTURE:
# Objective
[One clear sentence on the goal]

# Context & Inputs
[Relevant data, examples, or code snippets]

# Constraints & Rules
[Bullet points for "Must" and "Must Not" behaviors]

# Execution Plan
[A logical sequence for the LLM to follow]

# Output Format
[Define the required Markdown structure/style. Explicitly forbid JSON here if needed.]

The user's prompt to improve will be provided in the next message wrapped in <HUMAN_PROMPT> tags.
EOF

# Build config and call workflow handler
CONFIG=$(jq -n \
  --arg api_key "$OPENAI_API_KEY" \
  --arg model "gpt-4o-mini" \
  --arg system_prompt "$SYSTEM_PROMPT" \
  --arg spinner_msg "Improving promptâ€¦" \
  --arg success_msg "âœ… Improved! Prompt copied" \
  '{
    api_key: $api_key,
    model: $model,
    system_prompt: $system_prompt,
    user_transform: "wrap_prompt_tags",
    temperature: 1,
    spinner_msg: $spinner_msg,
    success_msg: $success_msg,
    notify_mode: "hud"
  }')

exec "$HOME/.raycast/bin/llm-workflow.sh" "$CONFIG"